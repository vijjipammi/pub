{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_recognition_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijjipammi/pub/blob/main/face_recognition_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhJsDJz8nmSj"
      },
      "source": [
        "pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWkH0zi-qy7E"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVnElPsmsqSt"
      },
      "source": [
        "import face_recognition\r\n",
        "image = face_recognition.load_image_file(\"/content/drive/MyDrive/face-reco/two_people.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9S1_hUZt2lD"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.figure(figsize=(14,14))\r\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMqTwcWEtp85"
      },
      "source": [
        "face_landmarks_list = face_recognition.face_landmarks(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4r-6ThmvC_P"
      },
      "source": [
        "face_landmarks_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKDFC715tpSq"
      },
      "source": [
        "print(\"There are {} faces.\".format(len(face_landmarks_list)))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s554X42euF7u"
      },
      "source": [
        "pil_image = Image.fromarray(image)\r\n",
        "d = ImageDraw.Draw(pil_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8xVm2FVuPdy"
      },
      "source": [
        "for face_landmarks in face_landmarks_list:\r\n",
        "\r\n",
        "    # Print the location of each facial feature in this image\r\n",
        "    for facial_feature in face_landmarks.keys():\r\n",
        "        print(\"The {} in this face has the following points: {}\".format(facial_feature, face_landmarks[facial_feature]))\r\n",
        "\r\n",
        "    # Let's trace out each facial feature in the image with a line!\r\n",
        "    for facial_feature in face_landmarks.keys():\r\n",
        "        d.line(face_landmarks[facial_feature], width=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzD2qfZyusS-"
      },
      "source": [
        "display(pil_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQkq07kGjp8W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLZrPHpUjqjR"
      },
      "source": [
        "## Create the Face Training/Face Embeddings\r\n",
        "\r\n",
        "* Train 5-10 Images here\r\n",
        "* Generate Known Face Encodings and\r\n",
        "* Corresponding Face Names\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18BV1L04u_i7"
      },
      "source": [
        "import face_recognition\r\n",
        "import numpy as np\r\n",
        "from PIL import Image, ImageDraw\r\n",
        "from IPython.display import display\r\n",
        "\r\n",
        "# This is an example of running face recognition on a single image\r\n",
        "# and drawing a box around each person that was identified.\r\n",
        "\r\n",
        "# Load a sample picture and learn how to recognize it.\r\n",
        "obama_image = face_recognition.load_image_file(\"/content/drive/MyDrive/face-reco/obama.jpg\")\r\n",
        "obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\r\n",
        "\r\n",
        "# Load a second sample picture and learn how to recognize it.\r\n",
        "biden_image = face_recognition.load_image_file(\"/content/drive/MyDrive/face-reco/biden.jpg\")\r\n",
        "biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\r\n",
        "\r\n",
        "# Create arrays of known face encodings and their names\r\n",
        "known_face_encodings = [\r\n",
        "    obama_face_encoding,\r\n",
        "    biden_face_encoding\r\n",
        "]\r\n",
        "known_face_names = [\r\n",
        "    \"Barack_Obama\",\r\n",
        "    \"Joe_Biden\"\r\n",
        "]\r\n",
        "\r\n",
        "\r\n",
        "print('Learned encoding for', len(known_face_encodings), 'images.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Z2mDzweJUZ"
      },
      "source": [
        "all_face_encodings = {}\r\n",
        "all_face_encodings[\"Barack_Obama\"]=obama_face_encoding\r\n",
        "all_face_encodings[\"Joe_Biden\"]=biden_face_encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUMevsg5gc4g"
      },
      "source": [
        "import pickle\r\n",
        "with open('dataset_faces.dat', 'wb') as f:\r\n",
        "    pickle.dump(all_face_encodings, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAq4KB_Zgi2x"
      },
      "source": [
        "with open('dataset_faces.dat', 'rb') as f:\r\n",
        "\tall_face_encodings = pickle.load(f)\r\n",
        "\r\n",
        "# Grab the list of names and the list of encodings\r\n",
        "known_face_names = list(all_face_encodings.keys())\r\n",
        "known_face_encodings = np.array(list(all_face_encodings.values()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8wUZyTY4qGa"
      },
      "source": [
        "# Load an image with an unknown face\r\n",
        "unknown_image = face_recognition.load_image_file(\"/content/drive/MyDrive/face-reco/two_people.jpg\")\r\n",
        "\r\n",
        "# Find all the faces and face encodings in the unknown image\r\n",
        "face_locations = face_recognition.face_locations(unknown_image)\r\n",
        "face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzfG7L8w4r2R"
      },
      "source": [
        "face_locations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbgLgz0j4uFk"
      },
      "source": [
        "face_encodings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jihxrP_Yc8mZ"
      },
      "source": [
        "  matches = face_recognition.compare_faces(known_face_encodings, face_encodings[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5DdO14zc-PD"
      },
      "source": [
        "matches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq9AF1-MdK8N"
      },
      "source": [
        "face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl0LvINgdOQK"
      },
      "source": [
        "face_distances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUY8-kUl2aHC"
      },
      "source": [
        "\r\n",
        "# Convert Uknown Image to PIL Format\r\n",
        "pil_image = Image.fromarray(unknown_image)\r\n",
        "\r\n",
        "# Create a Pillow ImageDraw Draw instance to draw with\r\n",
        "draw = ImageDraw.Draw(pil_image)\r\n",
        "\r\n",
        "# Loop through each face found in the unknown image\r\n",
        "for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\r\n",
        "    # See if the face is a match for the known face(s)\r\n",
        "    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\r\n",
        "\r\n",
        "    name = \"Unknown\"\r\n",
        "\r\n",
        "    # Or instead, use the known face with the smallest distance to the new face\r\n",
        "    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\r\n",
        "    best_match_index = np.argmin(face_distances)\r\n",
        "    \r\n",
        "    if matches[best_match_index]:\r\n",
        "        name = known_face_names[best_match_index]\r\n",
        "\r\n",
        "    # Draw a box around the face using the Pillow module\r\n",
        "    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\r\n",
        "\r\n",
        "    # Draw a label with a name below the face\r\n",
        "    text_width, text_height = draw.textsize(name)\r\n",
        "    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\r\n",
        "    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\r\n",
        "\r\n",
        "\r\n",
        "# Remove the drawing library from memory as per the Pillow docs\r\n",
        "del draw\r\n",
        "\r\n",
        "# Display the resulting image\r\n",
        "display(pil_image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}